{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Data Science\n",
    "\n",
    "[Gina Sprint](https://ginasprint.com/)\n",
    "\n",
    "# Pandas\n",
    "What are our learning objectives for this lesson?\n",
    "* Learn about the Pandas library\n",
    "* Work with `Series` and `DataFrame`objects\n",
    "\n",
    "## Acknowledgments\n",
    "Content used in this lesson is based upon information in the following sources:\n",
    "* [Pandas website](http://pandas.pydata.org/)\n",
    "* Python for Data Analysis by Wes McKinney"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm up Task(s)\n",
    "Open our main.py from last class: https://github.com/gsprint23/ZIME-Intro-to-Data-Science/blob/master/PandasFun You'll see that I posted the table practice problem solutions from last class' TODO in there too.\n",
    "1. Read the documentation on Pandas' `groupby()`: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html\n",
    "1. Add code main.py to get only Large group `DataFrame` and print it out\n",
    "1. Concept question: for any groupby, how do you know how many group `DataFrame` objects there are?\n",
    "    1. Challenge: how could you find this out programmatically? (lots of ways to solve this actually)\n",
    "\n",
    "## Today\n",
    "1. Finish PandasFun\n",
    "1. Pandas practice problems\n",
    "1. Break\n",
    "1. Data processing notes (cleaning, aggregating, etc.)\n",
    "1. Start project part 3\n",
    "\n",
    "## TODO\n",
    "1. For extra practice with pandas, work on the pandas practice problems below (not graded)\n",
    "1. Work on Quiz 4 in Moodle\n",
    "1. Work on project part 3: https://github.com/gsprint23/ZIME-Intro-to-Data-Science/blob/master/Project.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Practice Problems\n",
    "1. Create a CSV file called basketball.csv with the following data:\n",
    "```\n",
    "NAME,POS,GP,MIN,PTS\n",
    "Andrew Nembhard,G,25,760,272\n",
    "Anton Watson,F,25,448,206\n",
    "Ben Gregg,F,16,104,40\n",
    "Chet Holmgren,C,25,659,361\n",
    "Drew Timme,F,25,675,450\n",
    "Hunter Sallis,G,25,372,119\n",
    "Julian Strawther,G,25,647,308\n",
    "Kaden Perry,F,8,53,14\n",
    "Martynas Arlauskas,G,15,53,12\n",
    "Matthew Lang,G,16,52,17\n",
    "Nolan Hickman,G,25,474,156\n",
    "Rasir Bolton,G,25,654,271\n",
    "Will Graves,G,15,28,11\n",
    "```\n",
    "1. Load this CSV file into a Pandas DataFrame\n",
    "1. Add a new row for Joe Few. Example code:\n",
    "```\n",
    "new_row = pd.Series([\"G\",12,20,1], index=df.columns)\n",
    "new_row.name = \"Joe Few\"\n",
    "df = df.append(new_row)\n",
    "```\n",
    "1. Add a new column for CLASS (e.g. freshman, sophomore, junior, or senior). Here are the values:\n",
    "`[\"Sr\", \"Jr\", \"Fr\", \"Fr\", \"Jr\", \"Fr\", \"So\", \"Fr\", \"Jr\", \"Sr\", \"Fr\", \"Sr\", \"Sr\", \"Fr\"]`\n",
    "1. Create a Pandas Series with the count of each CLASS. E.g. for the modified dataset with Joe Few:\n",
    "```\n",
    "Fr    6\n",
    "Sr    4\n",
    "Jr    3\n",
    "So    1\n",
    "Name: Class, dtype: int64\n",
    "```\n",
    "1. Apply split-apply-combine to the PTS data\n",
    "    * Split on Class\n",
    "    * Apply the mean to the PTSs\n",
    "    * Combine the mean PTSs\n",
    "1. Write code to print out who has the most points per game. Check your work with the ESPN web page (at the time of this writing):\n",
    "\n",
    "![](https://raw.githubusercontent.com/GonzagaCPSC222/U5-Visualizing-Data/master/figures/team_leaders.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Overview\n",
    "From the [Pandas website](http://pandas.pydata.org/):\n",
    ">pandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\n",
    "\n",
    "The data structures objects in Pandas have axes that are *labeled*. This is quite useful for implementing software for data analytics. There are three main data structures objects in the Pandas library:\n",
    "1. `Series`: a one dimensional labeled array.\n",
    "1. `DataFrame`: a two dimensional labeled data structure.\n",
    "1. `Panel`: a three dimensional labeled data structure.\n",
    "\n",
    "In this class, we will mostly work with `Series` and `DataFrames`.\n",
    "\n",
    "Typically, we will import the Pandas library as pd:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Series`\n",
    "`Series` is a one dimensional labeled array. The axis labels are collectively referred to as the *index*. Each index value *maps* to a data item in the `Series`. You can think of a `Series` as being similar to an ordered dictionary augmented with data analysis functionality.\n",
    "\n",
    "Suppose we have a dictionary of city (key) and population (value) pairs that we want to convert into a `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bellevue       133992\n",
      "Leavenworth      1992\n",
      "Seattle        652405\n",
      "Spokane        210721\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "my_dict = {\"Seattle\": 652405, \"Spokane\": 210721, \"Bellevue\": 133992, \"Leavenworth\": 1992}\n",
    "ser = pd.Series(my_dict)\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the output, the left column is the index (the keys) and the right column is the data (values). The data type of the data (population) is int64.\n",
    "\n",
    "We can also pass in a list or an `ndarry`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "dtype: int64\n",
      "0    0.497088\n",
      "1    0.522258\n",
      "2    0.634724\n",
      "3   -0.006576\n",
      "4   -0.123352\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data = list([1, 2, 3, 4])\n",
    "ser = pd.Series(data)\n",
    "print(ser)\n",
    "\n",
    "import numpy as np\n",
    "data = np.random.randn(5)\n",
    "ser = pd.Series(data)\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the output, by default the index for a `Series` is numeric: integers starting at 0 and increasing by 1. We can explicitly set the index at instantiation time with the reserved keyword `index`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1.176157\n",
      "b   -0.398128\n",
      "c    1.163027\n",
      "d   -0.143429\n",
      "e   -1.024642\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "alpha = list(string.ascii_lowercase[:5])\n",
    "data = np.random.randn(5)\n",
    "ser = pd.Series(data, index=alpha)\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `name` Attribute\n",
    "Both the data and index of a `Series` can be named. We will see this is especially useful for integrating `Series` into `DataFrames`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bellevue       133992\n",
      "Leavenworth      1992\n",
      "Seattle        652405\n",
      "Spokane        210721\n",
      "dtype: int64\n",
      "After naming the data and index\n",
      "City\n",
      "Bellevue       133992\n",
      "Leavenworth      1992\n",
      "Seattle        652405\n",
      "Spokane        210721\n",
      "Name: Population, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "my_dict = {\"Seattle\": 652405, \"Spokane\": 210721, \"Bellevue\": 133992, \"Leavenworth\": 1992}\n",
    "ser = pd.Series(my_dict)\n",
    "print(ser)\n",
    "ser.name = \"Population\"\n",
    "ser.index.name = \"City\"\n",
    "print(\"After naming the data and index\")\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive and Summary Statistics\n",
    "Like Numpy ufuncs, Pandas objects (e.g. `Series` and `DataFrames`) included mathematical and statistical methods. Examples of such methods include:\n",
    "* `count()`: Count the number of non-NA values\n",
    "* `min()`, `max()`: Compute minimum and maximum values\n",
    "* `argmin()`, `argmax()`: Compute index locations (integers) at which minimum or maximum value obtained\n",
    "* `idxmin()`, `idxmax()`: Compute index values (labels) at which minimum or maximum value obtained\n",
    "* `quantile()`: Compute sample quantile ranging from 0 to 1\n",
    "* `sum()`: Sum of values\n",
    "* `cumsum()`: Cumulative sum of values\n",
    "* `mean()`: Mean of values\n",
    "* `median()`: Arithmetic median (50% quantile) of values\n",
    "* Many others!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarities between `Series` and `ndarray`\n",
    "`Series` is `ndarray`-like, which means `Series` is similar to `ndarray` in many ways, for example:\n",
    "* `Series` has attributes/methods/ similar to `ndarray`\n",
    "* You can pass a `Series` instead of an `ndarray` to most NumPy functions (ufuncs)\n",
    "    * Vectorization\n",
    "    * Overloaded operators\n",
    "* You can index and slice `Series` like `ndarray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bellevue       133992\n",
      "Leavenworth      1992\n",
      "Seattle        652405\n",
      "Spokane        210721\n",
      "dtype: int64\n",
      "ser.shape:(4,)\n",
      "ser.dtype:int64\n",
      "ser.mean():249777.5\n",
      "np.mean(ser):249777.5\n",
      "np.sqrt(ser):\n",
      "Bellevue       366.049177\n",
      "Leavenworth     44.631827\n",
      "Seattle        807.715915\n",
      "Spokane        459.043571\n",
      "dtype: float64\n",
      "ser + ser:\n",
      "Bellevue        267984\n",
      "Leavenworth       3984\n",
      "Seattle        1304810\n",
      "Spokane         421442\n",
      "dtype: int64\n",
      "ser * 10:\n",
      "Bellevue       1339920\n",
      "Leavenworth      19920\n",
      "Seattle        6524050\n",
      "Spokane        2107210\n",
      "dtype: int64\n",
      "Indexing ser[0]:133992\n",
      "Indexing ser[[0, 2]]:\n",
      "Bellevue    133992\n",
      "Seattle     652405\n",
      "dtype: int64\n",
      "Boolean indexing ser[[ser > ser.median()]]:\n",
      "Seattle    652405\n",
      "Spokane    210721\n",
      "dtype: int64\n",
      "Slicing ser[0:2]:\n",
      "Bellevue       133992\n",
      "Leavenworth      1992\n",
      "dtype: int64\n",
      "Slicing ser[2:]:\n",
      "Seattle    652405\n",
      "Spokane    210721\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "my_dict = {\"Seattle\": 652405, \"Spokane\": 210721, \"Bellevue\": 133992, \"Leavenworth\": 1992}\n",
    "ser = pd.Series(my_dict)\n",
    "print(ser)\n",
    "# attributes\n",
    "print(\"ser.shape:%s\" %(str(ser.shape)))\n",
    "print(\"ser.dtype:%s\" %(str(ser.dtype)))\n",
    "# methods\n",
    "print(\"ser.mean():%s\" %(str(ser.mean())))\n",
    "# numpy ufuncs\n",
    "print(\"np.mean(ser):%s\" %(str(np.mean(ser))))\n",
    "# vectorization\n",
    "print(\"np.sqrt(ser):\\n%s\" %(str(np.sqrt(ser))))\n",
    "print(\"ser + ser:\\n%s\" %(str(ser + ser)))\n",
    "print(\"ser * 10:\\n%s\" %(str(ser * 10)))\n",
    "# indeing\n",
    "print(\"Indexing ser[0]:%s\" %(str(ser[0])))\n",
    "print(\"Indexing ser[[0, 2]]:\\n%s\" %(str(ser[[0, 2]])))\n",
    "print(\"Boolean indexing ser[[ser > ser.median()]]:\\n%s\" %(str(ser[ser > ser.median()])))\n",
    "print(\"Slicing ser[0:2]:\\n%s\" %(str(ser[0:2])))\n",
    "print(\"Slicing ser[2:]:\\n%s\" %(str(ser[2:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences between `Series` and `ndarray`\n",
    "From the [Pandas website](http://pandas.pydata.org/):\n",
    "\n",
    ">A key difference between `Series` and `ndarray` is that operations between Series automatically align the data based on label. Thus, you can write computations without giving consideration to whether the Series involved have the same labels. The result of an operation between unaligned Series will have the union of the indexes involved. If a label is not found in one Series or the other, the result will be marked as missing NaN. Being able to write code without doing any explicit data alignment grants immense freedom and flexibility in interactive data analysis and research. The integrated data alignment features of the pandas data structures set pandas apart from the majority of related tools for working with labeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DataFrame`\n",
    "`DataFrame` is a two dimensional labeled data structure. `DataFrame` has index (just like `Series`). Each `DataFrame` index value *maps* to a labeled `Series`. You can think of a `DataFrame` like an Excel spreadsheet, SQL table, or a dict of `Series` objects. The index represents the rows and the `Series` represents the columns. \n",
    "\n",
    "Like Series, DataFrame accepts many different kinds of input:\n",
    "* Dictionary of 1D array-like objects (`ndarrays`, lists, dictionaries, or `Series`)\n",
    "* 2-D `ndarray`\n",
    "* Structured or record `ndarray`\n",
    "* A `Series`\n",
    "* Another `DataFrame`\n",
    "\n",
    "### `DataFrame` from Lists\n",
    "Let's expand our Washington city population `Series` example. Suppose we want to store the four most populated cities in Washington, Idaho, and Oregon. Let's declare dictionaries to store this new information. Then we will create a `DataFrame` to represent all three states' populations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0        1         2            3\n",
      "0   Seattle  Spokane    Tacoma    Vancouver\n",
      "1     Boise    Nampa  Meridian  Idaho Falls\n",
      "2  Portland   Eugene     Salem      Gresham\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "washington = [\"Seattle\", \"Spokane\", \"Tacoma\", \"Vancouver\"]\n",
    "idaho = [\"Boise\", \"Nampa\", \"Meridian\", \"Idaho Falls\"]\n",
    "oregon = [\"Portland\", \"Eugene\", \"Salem\", \"Gresham\"]\n",
    "pops = [washington, idaho, oregon]\n",
    "df = pd.DataFrame(pops)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas stacks the nested list into a 2-dimensional `DataFrame`. By default, the index and columns are labeled as 0-based indices. Instead, we want to provide labels to help with indexing later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population DataFrame #1\n",
      "           1        2         3            4\n",
      "WA   Seattle  Spokane    Tacoma    Vancouver\n",
      "ID     Boise    Nampa  Meridian  Idaho Falls\n",
      "OR  Portland   Eugene     Salem      Gresham\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df = pd.DataFrame(pops, index=[\"WA\", \"ID\", \"OR\"], columns=np.arange(1, len(washington) + 1))\n",
    "print(\"Population DataFrame #1\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataFrame` from Dictionaries\n",
    "Let's re-work the above example to build the `DataFrame` from dictionaries. This can be useful because the dictionary keys will be used for the `DataFrame` columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID        OR         WA\n",
      "0        Boise  Portland    Seattle\n",
      "1        Nampa    Eugene    Spokane\n",
      "2     Meridian     Salem     Tacoma\n",
      "3  Idaho Falls   Gresham  Vancouver\n"
     ]
    }
   ],
   "source": [
    "pops_dict = {\"WA\": washington, \"ID\": idaho, \"OR\": oregon}\n",
    "df2 = pd.DataFrame(pops_dict)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then update the index to start at 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population DataFrame #2\n",
      "            ID        OR         WA\n",
      "1        Boise  Portland    Seattle\n",
      "2        Nampa    Eugene    Spokane\n",
      "3     Meridian     Salem     Tacoma\n",
      "4  Idaho Falls   Gresham  Vancouver\n"
     ]
    }
   ],
   "source": [
    "df2.index += 1\n",
    "print(\"Population DataFrame #2\")\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `df` (Population `DataFrame` #1) and `df2` (Population `DataFrame` #2) are the transpose of each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           1        2         3            4\n",
      "ID     Boise    Nampa  Meridian  Idaho Falls\n",
      "OR  Portland   Eugene     Salem      Gresham\n",
      "WA   Seattle  Spokane    Tacoma    Vancouver\n",
      "           1        2         3            4\n",
      "ID     Boise    Nampa  Meridian  Idaho Falls\n",
      "OR  Portland   Eugene     Salem      Gresham\n",
      "WA   Seattle  Spokane    Tacoma    Vancouver\n",
      "       1     2     3     4\n",
      "ID  True  True  True  True\n",
      "OR  True  True  True  True\n",
      "WA  True  True  True  True\n"
     ]
    }
   ],
   "source": [
    "df2T = df2.T # transpose\n",
    "# re-order\n",
    "df = df.sort_index()\n",
    "df2T = df2T.sort_index()\n",
    "print(df)\n",
    "print(df2T)\n",
    "print(df == df2T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if the dictionaries used to create a `DataFrame` do not have the same keys? Just like with `Series`, the `DataFrame` index of unaligned columns will be the union of the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ID        OR        WA\n",
      "Bellevue            NaN       NaN  133992.0\n",
      "Boise          205671.0       NaN       NaN\n",
      "Coeur d'Alene   44137.0       NaN       NaN\n",
      "Corvallis           NaN   54462.0       NaN\n",
      "Eugene              NaN  156185.0       NaN\n",
      "Hillsboro           NaN   91611.0       NaN\n",
      "Leavenworth         NaN       NaN    1992.0\n",
      "Moscow          23800.0       NaN       NaN\n",
      "Nampa           81557.0       NaN       NaN\n",
      "Portland            NaN  583776.0       NaN\n",
      "Seattle             NaN       NaN  652405.0\n",
      "Spokane             NaN       NaN  210721.0\n"
     ]
    }
   ],
   "source": [
    "washington = {\"Seattle\": 652405, \"Spokane\": 210721, \"Bellevue\": 133992, \"Leavenworth\": 1992}\n",
    "idaho = {\"Boise\": 205671, \"Nampa\": 81557, \"Coeur d'Alene\": 44137, \"Moscow\": 23800}\n",
    "oregon = {\"Portland\": 583776, \"Eugene\": 156185, \"Hillsboro\": 91611, \"Corvallis\": 54462}\n",
    "pops = {\"WA\": washington, \"ID\": idaho, \"OR\": oregon}\n",
    "df = pd.DataFrame(pops)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataFrame` from `ndarray`\n",
    "As another example, let's create a `DataFrame` from random data stored in an `ndarray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1      col2      col3      col4\n",
      "a  1.108062  0.670847  1.108137 -0.250980\n",
      "b  0.183961 -1.714299 -0.739520 -0.319820\n",
      "c  1.286052 -0.927832  1.650807  0.895659\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import randn\n",
    "rand_data = randn(3, 4)\n",
    "rand_df = pd.DataFrame(rand_data, index=[\"a\", \"b\", \"c\"], columns=[\"col1\", \"col2\", \"col3\", \"col4\"])\n",
    "print(rand_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Columns\n",
    "You can treat a `DataFrame` semantically like a dictionary of like-indexed `Series` objects. Getting, setting, and deleting columns works with the same syntax as the analogous dictionary operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1      col2      col3      col4\n",
      "a -0.013056 -0.718166  1.628721  1.705919\n",
      "b -0.449616  0.158878  0.592754  0.000759\n",
      "c  0.151376  0.967503 -0.941538 -0.499192\n",
      "a   -0.718166\n",
      "b    0.158878\n",
      "c    0.967503\n",
      "Name: col2, dtype: float64\n",
      "       col1      col2      col3  col4\n",
      "a -0.013056 -0.718166  1.628721   100\n",
      "b -0.449616  0.158878  0.592754   100\n",
      "c  0.151376  0.967503 -0.941538   100\n",
      "       col1      col2      col3  col4   col5\n",
      "a -0.013056 -0.718166  1.628721   100   True\n",
      "b -0.449616  0.158878  0.592754   100  False\n",
      "c  0.151376  0.967503 -0.941538   100  False\n",
      "       col1      col2      col3  col4   col5         sum\n",
      "a -0.013056 -0.718166  1.628721   100   True  101.897499\n",
      "b -0.449616  0.158878  0.592754   100  False  100.302016\n",
      "c  0.151376  0.967503 -0.941538   100  False  100.177341\n",
      "       col1      col2  ones      col3  col4   col5         sum\n",
      "a -0.013056 -0.718166     1  1.628721   100   True  101.897499\n",
      "b -0.449616  0.158878     1  0.592754   100  False  100.302016\n",
      "c  0.151376  0.967503     1 -0.941538   100  False  100.177341\n",
      "       col1      col2  ones      col3  col4         sum\n",
      "a -0.013056 -0.718166     1  1.628721   100  101.897499\n",
      "b -0.449616  0.158878     1  0.592754   100  100.302016\n",
      "c  0.151376  0.967503     1 -0.941538   100  100.177341\n",
      "       col1      col2  ones      col3  col4\n",
      "a -0.013056 -0.718166     1  1.628721   100\n",
      "b -0.449616  0.158878     1  0.592754   100\n",
      "c  0.151376  0.967503     1 -0.941538   100\n",
      "Popped column is a Series:\n",
      "a    101.897499\n",
      "b    100.302016\n",
      "c    100.177341\n",
      "Name: sum, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "rand_data = randn(3, 4)\n",
    "rand_df = pd.DataFrame(rand_data, index=[\"a\", \"b\", \"c\"], columns=[\"col1\", \"col2\", \"col3\", \"col4\"])\n",
    "print(rand_df)\n",
    "\n",
    "# index column\n",
    "print(rand_df[\"col2\"])\n",
    "# update column\n",
    "rand_df[\"col4\"] = 100 # 100 is propogated to fill the column\n",
    "print(rand_df)\n",
    "# add columns (inserted at end)\n",
    "rand_df[\"col5\"] = rand_df[\"col1\"] > rand_df[\"col2\"]\n",
    "print(rand_df)\n",
    "rand_df[\"sum\"] = rand_df.sum(axis=\"columns\")\n",
    "print(rand_df)\n",
    "# add columns at location\n",
    "rand_df.insert(2, \"ones\", 1)\n",
    "print(rand_df)\n",
    "# delete columns\n",
    "del rand_df[\"col5\"]\n",
    "print(rand_df)\n",
    "sum_ser = rand_df.pop(\"sum\")\n",
    "print(rand_df)\n",
    "print(\"Popped column is a Series:\")\n",
    "print(sum_ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "From the [Pandas website](http://pandas.pydata.org/), the basics of indexing are as follows:\n",
    "\n",
    "|Operation|Syntax|Result|\n",
    "|-|-|-|\n",
    "|Select column\t|`df[col]`\t|`Series`|\n",
    "|Select row by label\t|`df.loc[label]`|\t`Series`|\n",
    "|Select row by integer location\t|`df.iloc[loc]`\t|`Series`|\n",
    "|Slice rows\t|`df[5:10]`\t|`DataFrame`|\n",
    "|Select rows by boolean vector\t|`df[bool_vec]`|\t`DataFrame`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1      col2      col3      col4\n",
      "a  0.084633  0.604611  0.666690  0.043860\n",
      "b -1.742362  1.355383  1.167826  0.491943\n",
      "c  0.746066 -1.503622 -0.663647 -0.463522\n",
      "col1   -1.742362\n",
      "col2    1.355383\n",
      "col3    1.167826\n",
      "col4    0.491943\n",
      "Name: b, dtype: float64\n",
      "col1   -1.742362\n",
      "col2    1.355383\n",
      "col3    1.167826\n",
      "col4    0.491943\n",
      "Name: b, dtype: float64\n",
      "       col1      col2      col3      col4\n",
      "a  0.084633  0.604611  0.666690  0.043860\n",
      "b -1.742362  1.355383  1.167826  0.491943\n"
     ]
    }
   ],
   "source": [
    "rand_data = randn(3, 4)\n",
    "rand_df = pd.DataFrame(rand_data, index=[\"a\", \"b\", \"c\"], columns=[\"col1\", \"col2\", \"col3\", \"col4\"])\n",
    "print(rand_df)\n",
    "\n",
    "# row indexing by label\n",
    "print(rand_df.loc[\"b\"])\n",
    "# row indexing by location\n",
    "print(rand_df.iloc[1])\n",
    "# row slicing by location\n",
    "print(rand_df[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining `DataFrame`s\n",
    "Pandas supports many ways to combine `DataFrame`s together, including merging, joining, and concatenating. For simplicity, we will focus on concatenation with the `concat` function in the main Pandas namespace. \n",
    "\n",
    "Suppose we have three `DataFrame`s with the same column labels that we want to combine into a single `DataFrame`. We can use `pd.concat(<list of DataFrames>)` to combine them. The following example is from the Pandas documentation on [merging](http://pandas.pydata.org/pandas-docs/stable/merging.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B    C    D\n",
      "10  A10  B10  C10  D10\n",
      "11  A11  B11  C11  D11\n",
      "Help on method tail in module pandas.core.generic:\n",
      "\n",
      "tail(n=5) method of pandas.core.frame.DataFrame instance\n",
      "    Returns last n rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "index=[0, 1, 2, 3])\n",
    "\n",
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "index=[4, 5, 6, 7])\n",
    "\n",
    "df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n",
    "'B': ['B8', 'B9', 'B10', 'B11'],\n",
    "'C': ['C8', 'C9', 'C10', 'C11'],\n",
    "'D': ['D8', 'D9', 'D10', 'D11']},\n",
    "index=[8, 9, 10, 11])\n",
    "\n",
    "frames = [df1, df2, df3]\n",
    "result = pd.concat(frames)\n",
    "print(result.tail(2))\n",
    "print(help(result.tail))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting `DataFrame` is a combination is `df3` concatenated to the end of `df2`, which is concatenated to the end of `df1`:\n",
    "![](http://pandas.pydata.org/pandas-docs/stable/_images/merging_concat_basic.png)\n",
    "(image from [http://pandas.pydata.org/pandas-docs/stable/_images/merging_concat_basic.png](http://pandas.pydata.org/pandas-docs/stable/_images/merging_concat_basic.png))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Large `DataFrame`s\n",
    "In this class we will be working with some big `DataFrame`s. Pandas will output condensed `DataFrame`s using .... There are also object methods to view shortened or summarized `DataFrame` information:\n",
    "* `describe()`: Generate various summary statistics, excluding NaN values\n",
    "* `head(n=5)`: Returns first `n` rows \n",
    "* `tail(n=5)`: Returns the last `n` rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         A   B   C   D\n",
      "count   12  12  12  12\n",
      "unique  12  12  12  12\n",
      "top     A8  B2  C5  D7\n",
      "freq     1   1   1   1\n",
      "\n",
      "\n",
      "    A   B   C   D\n",
      "0  A0  B0  C0  D0\n",
      "1  A1  B1  C1  D1\n",
      "\n",
      "\n",
      "      A    B    C    D\n",
      "10  A10  B10  C10  D10\n",
      "11  A11  B11  C11  D11\n"
     ]
    }
   ],
   "source": [
    "print(result.describe())\n",
    "print(\"\\n\")\n",
    "print(result.head(n=2))\n",
    "print(\"\\n\")\n",
    "print(result.tail(n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File I/O\n",
    "With Pandas, we can easily write our data frames out to a csv (comma separated value) file to save for later use after our program terminates. The `DataFrame` method [`to_csv()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html) write a data frame to a csv file. The rows and columns of the data frame will be the rows and columns of the csv file. \n",
    "\n",
    "For example, suppose we want to write to a file our example data frame we used to learn how to concatenate data frames together. We can do this in a one-liner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fname = r\"files\\results_df.csv\"\n",
    "result.to_csv(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we open results_df.csv with Microsoft Excel, we see the following table:\n",
    "<img src=\"https://raw.githubusercontent.com/gsprint23/cpts215/master/lessons/figures/results_df.png\" width=\"400\">\n",
    "\n",
    "We can also load data from a csv file into a data frame. To do this, we use the [`read_csv()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) Pandas function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0    A    B    C    D\n",
      "0            0   A0   B0   C0   D0\n",
      "1            1   A1   B1   C1   D1\n",
      "2            2   A2   B2   C2   D2\n",
      "3            3   A3   B3   C3   D3\n",
      "4            4   A4   B4   C4   D4\n",
      "5            5   A5   B5   C5   D5\n",
      "6            6   A6   B6   C6   D6\n",
      "7            7   A7   B7   C7   D7\n",
      "8            8   A8   B8   C8   D8\n",
      "9            9   A9   B9   C9   D9\n",
      "10          10  A10  B10  C10  D10\n",
      "11          11  A11  B11  C11  D11\n",
      "Index(['Unnamed: 0', 'A', 'B', 'C', 'D'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(fname)\n",
    "print(df)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we seem some less than desirable output. For example, the first column in the csv file is our index, but our data frame is creating and assigning a new index. We also have the extra column \"Unnamed: 0\". We can explicitly tell Pandas the first column is the index with the keyword `index_col`. It is also good to explicitly tell Pandas the first row is our header row and contains the column labels. We can do this with the keyword `header`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B    C    D\n",
      "0    A0   B0   C0   D0\n",
      "1    A1   B1   C1   D1\n",
      "2    A2   B2   C2   D2\n",
      "3    A3   B3   C3   D3\n",
      "4    A4   B4   C4   D4\n",
      "5    A5   B5   C5   D5\n",
      "6    A6   B6   C6   D6\n",
      "7    A7   B7   C7   D7\n",
      "8    A8   B8   C8   D8\n",
      "9    A9   B9   C9   D9\n",
      "10  A10  B10  C10  D10\n",
      "11  A11  B11  C11  D11\n",
      "Index(['A', 'B', 'C', 'D'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# another attempt at reading in the csv data\n",
    "df = pd.read_csv(fname, index_col=0, header=0)\n",
    "print(df)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "We have covered quite a bit of information on Pandas, but we have only scratched the surface! I highly encourage you to read *Python for Data Analysis* by Wes McKinney and practice working with `Series` and `DataFrame` objects. Over the course of the semester we will learn new Pandas functionality as we go. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
